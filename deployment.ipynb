{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Reshape, UpSampling2D, \\\n",
    "    BatchNormalization, Activation, Input, LeakyReLU, Dropout, Flatten, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from scipy.linalg import sqrtm\n",
    "from skimage.transform import resize\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN:\n",
    "    def __init__(self, img_rows, img_cols, channels, num_classes, z, discriminator_steps=2, generator_steps=3):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.num_classes = num_classes\n",
    "        self.latent_dim = z\n",
    "        self.discriminator_steps = discriminator_steps\n",
    "        self.generator_steps = generator_steps\n",
    "        self.img_shape = (img_rows, img_cols, channels)\n",
    "        self.build_and_compile_models()\n",
    "    \n",
    "    def build_generator(self):\n",
    "        \"\"\"Build a Generator Model\"\"\"\n",
    "        inputs = Input(shape=(self.latent_dim,))\n",
    "        labels = Input(shape=(self.num_classes,))\n",
    "        image_size = self.img_rows\n",
    "        \n",
    "        # Concatenate noise and label\n",
    "        x = concatenate([inputs, labels], axis=1)\n",
    "        x = Dense(image_size // 4 * image_size // 4 * 128)(x)\n",
    "        x = Reshape((image_size // 4, image_size // 4, 128))(x)\n",
    "\n",
    "        for filters in [128, 64, 32, self.channels]:\n",
    "            strides = 2 if filters > 32 else 1\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = Conv2DTranspose(filters=filters, kernel_size=5, strides=strides, padding='same')(x)\n",
    "\n",
    "        x = Activation('tanh')(x)\n",
    "        generator = Model([inputs, labels], x, name='generator')\n",
    "        generator.summary()\n",
    "        return generator\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        \"\"\"Build a Discriminator Model\"\"\"\n",
    "        inputs = Input(shape=self.img_shape)\n",
    "        labels = Input(shape=(self.num_classes,))\n",
    "        image_size = self.img_rows\n",
    "        \n",
    "        # Embed the labels\n",
    "        y = Dense(image_size * image_size)(labels)  # Ensure this matches the flattened size\n",
    "        y = Reshape((image_size, image_size, 1))(y)  # Correct shape\n",
    "        \n",
    "        x = concatenate([inputs, y])\n",
    "\n",
    "        for filters in [32, 64, 128, 256]:\n",
    "            strides = 2 if filters != 256 else 1\n",
    "            x = Conv2D(filters=filters, kernel_size=5, strides=strides, padding='same')(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "            x = Dropout(0.4)(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation('sigmoid')(x)\n",
    "        discriminator = Model([inputs, labels], x, name='discriminator')\n",
    "        discriminator.summary()\n",
    "        return discriminator\n",
    "\n",
    "\n",
    "    def build_and_compile_models(self):\n",
    "        \"\"\"Build and compile Generator and Discriminator models\"\"\"\n",
    "        # Build discriminator model\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # Build generator model\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # Build adversarial model\n",
    "        self.discriminator.trainable = False\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(self.num_classes,))\n",
    "        img = self.generator([noise, label])\n",
    "        validity = self.discriminator([img, label])\n",
    "        self.combined = Model([noise, label], validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 784)          21168       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 28, 28, 1)    0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 28, 2)    0           ['input_1[0][0]',                \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 32)   1632        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 14, 14, 32)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 14, 14, 32)   0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 7, 7, 64)     51264       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 7, 7, 64)     0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 7, 7, 64)     0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 4, 4, 128)    204928      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 4, 4, 128)    0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 4, 128)    0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 4, 4, 256)    819456      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 4, 4, 256)    0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 4, 256)    0           ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4096)         0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            4097        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1)            0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,102,545\n",
      "Trainable params: 1,102,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 26)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 126)          0           ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6272)         796544      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 7, 7, 128)    0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 7, 7, 128)   512         ['reshape_1[0][0]']              \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 7, 7, 128)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 14, 14, 128)  409728     ['activation_1[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 14, 14, 128)  512        ['conv2d_transpose[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 14, 14, 128)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 28, 28, 64)  204864      ['activation_2[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 64)  256         ['conv2d_transpose_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 28, 28, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 28, 28, 32)  51232       ['activation_3[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 28, 32)  128         ['conv2d_transpose_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 28, 28, 32)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 28, 28, 1)   801         ['activation_4[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 28, 28, 1)    0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,464,577\n",
      "Trainable params: 1,463,873\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CGAN\n",
    "cgan = CGAN(img_rows=28, img_cols=28, channels=1, num_classes=26, z=100)\n",
    "\n",
    "# Load the weights into the generator, discriminator, or combined model\n",
    "cgan.combined.load_weights('cgan_train_weights/cgan_Epoch_4900_combined.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment to render process (show render link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('gpu_env2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0a3af42ef8501fea43ae82c69a76947ce629ad9116488b83f3db197cea30a60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
